{
'id': 'bugs.core_3537',
'qmid': None,
'tracker_id': 'CORE-3537',
'title': "There is no need to undo changes made in GTT created with ON COMMIT DELETE ROWS option when transaction is rolled back",
'description': 
 """
   19.12.2016. 
   After discuss with hvlad it was decided to use fetches & marks values that are issued in trace 
   ROLLBACK_TRANSACTION statistics and evaluate ratio of these values with:
   1) number of inserted rows(see 'NUM_ROWS_TO_BE_ADDED' constant);
   2) number of data pages that table occupies (it's retieved via 'gstat -t T_FIX_TAB').

   We use three tables with the same DDL: permanent ('t_fix_tab'), GTT PRESERVE and GTT DELETE rows.
   All these tables are subject to DML which does insert rows.
   Permanent table is used for retrieving statistics of data pages that are in use after this DML.
   Number of rows that we add into tables should not be very high, otherwise rollback will be done via TIP,
   i.e. without real undone actions ==> we will not see proper ratios. 
   After serveral runs it was decided to use value = 45000 (rows).

   All ratios should belong to some range with +/-5% of possible difference from one run to another.
   Concrete values of ratio were found after several runs on 2.5.7, 3.0.2 & 4.0.0

   Checked on 2.5.7.27030 (SS/SC), WI-V3.0.2.32644 (SS/SC/CS) and WI-T4.0.0.468 (SS/SC).

   Notes.
   1. We can estimate volume of UNDO changes in trace statistics for ROLLBACK event.
      This statistics was added since 2.5.2 (see CORE-3598).
   2. We have to use 'gstat -t <table>'instead of 'fbsvcmgr sts_table <...>'in 2.5.x - see CORE-5426.

 """,
'min_versions': '2.5.2',
'versions': [
{
 'firebird_version': '2.5',
 'platform': 'All',
 'page_size': '4096',
 'test_type': 'Python',
 'init_script':
  """
    create or alter procedure sp_fill_fix_tab as begin end;
    create or alter procedure sp_fill_gtt_del_rows as begin end;
    create or alter procedure sp_fill_gtt_sav_rows as begin end;

    recreate view v_field_len as
    select rf.rdb$relation_name as rel_name, f.rdb$field_length as fld_len
    from rdb$relation_fields rf
    join rdb$fields f on rf.rdb$field_source = f.rdb$field_name
    ;

    recreate table t_fix_tab(
      s1 varchar(50)
      -- unique using index t_fix_tab_s1
    );

    recreate global temporary table t_gtt_del_rows(
      s1 varchar(50)
      -- unique using index t_gtt_del_rows_s1
    ) on commit DELETE rows;
    
    recreate global temporary table t_gtt_sav_rows(
      s1 varchar(50)
      -- unique using index t_gtt_sav_rows_s1
    ) on commit PRESERVE rows;
    
    commit;

    set term ^;
    create or alter procedure sp_fill_fix_tab(a_rows int) as
        declare k int;
        declare w int;
    begin
        k=a_rows;
        select v.fld_len from v_field_len v where v.rel_name=upper('t_fix_tab') into w;
        while(k>0) do insert into t_fix_tab(s1) values( rpad('', :w, uuid_to_char(gen_uuid()) ) ) returning :k-1 into k;
    end
    ^
    create or alter procedure sp_fill_gtt_del_rows(a_rows int) as
        declare k int;
        declare w int;
    begin
        k=a_rows;
        select v.fld_len from v_field_len v where v.rel_name=upper('t_gtt_del_rows') into w;
        while(k>0) do insert into t_gtt_del_rows(s1) values( rpad('', :w, uuid_to_char(gen_uuid()) ) ) returning :k-1 into k;
    end
    ^
    create or alter procedure sp_fill_gtt_sav_rows(a_rows int) as
        declare k int;
        declare w int;
    begin
        k=a_rows;
        select v.fld_len from v_field_len v where v.rel_name=upper('t_gtt_sav_rows') into w;
        while(k>0) do insert into t_gtt_sav_rows(s1) values( rpad('', :w, uuid_to_char(gen_uuid()) ) ) returning :k-1 into k;
    end
    ^
    set term ;^
    commit;
  """,
 'test_script':
  """
import os
import subprocess
import time
from fdb import services
from subprocess import Popen

os.environ["ISC_USER"] = user_name
os.environ["ISC_PASSWORD"] = user_password

# Obtain engine version:
engine = str(db_conn.engine_version) # convert to text because 'float' object has no attribute 'startswith'
db_conn.close()

# NB, 06.12.2016: as of  fdb 1.6.1 one need to EXPLICITLY specify user+password pair when doing connect 
# via to FB services API by services.connect() - see FB tracker, PYFB-69
# ("Can not connect to FB services if set ISC_USER & ISC_PASSWORD by os.environ[ ... ]")

fb_home = services.connect(host='localhost', user= user_name, password= user_password).get_home_directory()
# fb_home = services.connect(host='localhost').get_home_directory()

if engine.startswith('2.5'):
  fb_home = fb_home + 'bin'+os.sep


# Change FW to OFF in order to speed up initial data filling:
##################
db_file="$(DATABASE_LOCATION)bugs.core_3537.fdb"

fn_nul = open(os.devnull, 'w')

subprocess.call([ fb_home+"fbsvcmgr", "localhost:service_mgr",
                  "action_properties", "prp_write_mode", "prp_wm_async",
                  "dbname", db_file ],
                  stdout = fn_nul,
                  stderr = subprocess.STDOUT
               )

fn_nul.close()



# ::: NB ::: Trace config file format in 3.0 differs from 2.5 one:
# 1) header section must be enclosed in "[" and "]",
# 2) parameter-value pairs must be separated with '=' sign:
#    services
#    {
#      parameter =  value
#    }

if engine.startswith('2.5'):
    txt = '''# Generated auto, do not edit!
      <database %[\\\\\\\\/]security?.fdb>
          enabled false
      </database>

      <database %[\\\\\\\\/]bugs.core_3537.fdb>
          enabled true
          time_threshold 0
          log_transactions true
          #log_procedure_finish true
          print_perf true
      </database>
    '''
else:
    txt = '''# Generated auto, do not edit!
      database=%[\\\\\\\\/]security?.fdb
      {
          enabled = false
      }
      database=%[\\\\\\\\/]bugs.core_3537.fdb
      {
          enabled = true
          time_threshold = 0
          log_transactions = true
          print_perf = true
      }
    '''

f_trc_cfg=open( os.path.join(context['temp_directory'],'tmp_trace_3537.cfg'), 'w')
f_trc_cfg.write(txt)
f_trc_cfg.close()

NUM_ROWS_TO_BE_ADDED = 45000

con1 = fdb.connect(dsn=dsn)
cur1=con1.cursor()

# Make initial data filling into PERMANENT table for retrieving later number of data pages
# (it should be the same for any kind of tables, including GTTs):
cur1.callproc('sp_fill_fix_tab', (NUM_ROWS_TO_BE_ADDED,))
con1.commit()

# ##############################################################
# S T A R T   T R A C E   i n   S E P A R A T E    P R O C E S S
# ##############################################################

f_trc_log=open( os.path.join(context['temp_directory'],'tmp_trace_3537.log'), "w")
f_trc_err=open( os.path.join(context['temp_directory'],'tmp_trace_3537.err'), "w")

p_trace = Popen( [ fb_home+'fbsvcmgr', 'localhost:service_mgr', 'action_trace_start' , 'trc_cfg', f_trc_cfg.name],stdout=f_trc_log,stderr=f_trc_err)

time.sleep(1)

cur1.callproc('sp_fill_gtt_sav_rows', (NUM_ROWS_TO_BE_ADDED,))
con1.rollback()
cur1.callproc('sp_fill_gtt_del_rows', (NUM_ROWS_TO_BE_ADDED,))
con1.rollback()
con1.close()


# ####################################################
# G E T  A C T I V E   T R A C E   S E S S I O N   I D
# ####################################################
# Save active trace session info into file for further parsing it and obtain session_id back (for stop):

f_trc_lst = open( os.path.join(context['temp_directory'],'tmp_trace_3537.lst'), 'w')
subprocess.call([fb_home+'fbsvcmgr', 'localhost:service_mgr', 'action_trace_list'], stdout=f_trc_lst)
f_trc_lst.close()

# !!! DO NOT REMOVE THIS LINE !!!
time.sleep(1)

trcssn=0
with open( f_trc_lst.name,'r') as f:
    for line in f:
        i=1
        if 'Session ID' in line:
            for word in line.split():
                if i==3:
                    trcssn=word
                i=i+1
            break
f.close()
# Result: `trcssn` is ID of active trace session. Now we have to terminate it:

# ####################################################
# S E N D   R E Q U E S T    T R A C E   T O   S T O P
# ####################################################
if trcssn>0:
    fn_nul = open(os.devnull, 'w')
    subprocess.call([fb_home+'fbsvcmgr', 'localhost:service_mgr', 'action_trace_stop','trc_id', trcssn], stdout=fn_nul)
    fn_nul.close()
    # DO NOT REMOVE THIS LINE:
    time.sleep(2)

p_trace.terminate()
f_trc_log.close()
f_trc_err.close()

###################
# Obtain statistics for table T_FIX_TAB in order to estimate numberof data pages
###################

f_stat_log = open( os.path.join(context['temp_directory'],'tmp_stat_3537.log'), 'w')
f_stat_err = open( os.path.join(context['temp_directory'],'tmp_stat_3537.err'), 'w')

subprocess.call( [ fb_home+"gstat", dsn, "-t",  't_fix_tab'.upper() ],
                 stdout = f_stat_log,
                 stderr = f_stat_err
               )
f_stat_log.close()
f_stat_err.close()

# Following files should be EMPTY:
#################

f_list=[f_stat_err, f_trc_err]
for i in range(len(f_list)):
   f_name=f_list[i].name
   if os.path.getsize(f_name) > 0:
       with open( f_name,'r') as f:
           for line in f:
               print("Unexpected STDERR, file "+f_name+": "+line)
       f.close()


dp_cnt=-1
with open( f_stat_log.name,'r') as f:
  for line in f:
    if 'data pages' in line.lower():
       # Data pages: 1098, data page slots: 1098, average fill: 74% ==> 1098
       dp_cnt = int(line.replace(',',' ').split()[2])
       
f.close()

gtt_sav_fetches=-1
gtt_sav_marks = -1
gtt_del_fetches=-1
gtt_del_marks = -1
gtt_del_trace = ''
gtt_sav_trace = ''

with open( f_trc_log.name,'r') as f:
  for line in f:
    if 'fetch' in line:
       # 2.5.7:
       # ['370', 'ms,', '1100', 'read(s),', '1358', 'write(s),', '410489', 'fetch(es),', '93294', 'mark(s)']
       # ['2', 'ms,', '1', 'read(s),', '257', 'write(s),', '1105', 'fetch(es),', '1102', 'mark(s)']
       # 3.0.2:
       # 618 ms, 1 read(s), 2210 write(s), 231593 fetch(es), 92334 mark(s)
       # 14 ms, 1109 write(s), 7 fetch(es), 4 mark(s)
       words = line.split()
       for k in range(len(words)):
         if words[k].startswith('fetch'):
           if gtt_sav_fetches == -1:
             gtt_sav_fetches = int( words[k-1] )
             gtt_sav_trace = line.strip()
           else:
             gtt_del_fetches = int( words[k-1] )
             gtt_del_trace = line.strip()

         if words[k].startswith('mark'):
           if gtt_sav_marks==-1:
             gtt_sav_marks = int( words[k-1] )
           else:
             gtt_del_marks = int( words[k-1] )

                                                                        #  2.5.7      3.0.2, 4.0.0
                                                                        # ---------------------
'''
fetches2rows_gtt_sav = (1.00 * gtt_sav_fetches / NUM_ROWS_TO_BE_ADDED,   9.1219,      5.1465  )
fetches2rows_gtt_del = (1.00 * gtt_del_fetches / NUM_ROWS_TO_BE_ADDED,   0.0245,      0.00015 )
marks2rows_gtt_sav = (1.00 * gtt_sav_marks / NUM_ROWS_TO_BE_ADDED,       2.0732,      2.05186 )
marks2rows_gtt_del = (1.00 * gtt_del_marks / NUM_ROWS_TO_BE_ADDED,       0.0245,      0.000089 )
                                                                   
fetches2dp_gtt_sav = (1.00 * gtt_sav_fetches / dp_cnt,                   373.85,      209.776 )
fetches2dp_gtt_del = (1.00 * gtt_del_fetches / dp_cnt,                   1.0063,      0.00634 )
marks2dp_gtt_sav = (1.00 * gtt_sav_marks / dp_cnt,                       84.9672,     83.6358 )
marks2dp_gtt_del = (1.00 * gtt_del_marks / dp_cnt,                       1.0036,      0.00362 )
'''
                                                                           #  2.5.7      3.0.2, 4.0.0
                                                                           # ------------------------
check_data={
   'fetches2rows_gtt_sav' : (1.00 * gtt_sav_fetches / NUM_ROWS_TO_BE_ADDED,   9.1219,      5.1465  )
  ,'fetches2rows_gtt_del' : (1.00 * gtt_del_fetches / NUM_ROWS_TO_BE_ADDED,   0.0245,      0.00015 )
  ,'marks2rows_gtt_sav' : (1.00 * gtt_sav_marks / NUM_ROWS_TO_BE_ADDED,       2.0732,      2.05186 )
  ,'marks2rows_gtt_del' : (1.00 * gtt_del_marks / NUM_ROWS_TO_BE_ADDED,       0.0245,      0.000089 )
  ,'fetches2dp_gtt_sav' : (1.00 * gtt_sav_fetches / dp_cnt,                   373.85,      209.776 )
  ,'fetches2dp_gtt_del' : (1.00 * gtt_del_fetches / dp_cnt,                   1.0063,      0.00634 )
  ,'marks2dp_gtt_sav' : (1.00 * gtt_sav_marks / dp_cnt,                       84.9672,     83.6358 )
  ,'marks2dp_gtt_del' : (1.00 * gtt_del_marks / dp_cnt,                       1.0036,      0.00362 )
}


i = 1 if engine.startswith('2.5') else 2
mult = 1.05
fail = False
for k, v in sorted(check_data.iteritems()):
  msg = ( 'Check ' + k + ': ' + 
          ( 'OK' if v[i]/mult <=v[0] <= v[i]*mult
            else 'value '+str(v[0])+' not in range '+str(v[i]) + ' +/-'+str(mult*100-100)+'%'
          )
        )
  print(msg)
  failed_flag = ('not in range' in msg)

if failed_flag:
   print('Trace for GTT PRESERVE rows: ' + gtt_sav_trace)
   print('Trace for GTT DELETE   rows: ' + gtt_del_trace)

# CLEANUP
#########

f_list=[f_trc_cfg, f_trc_lst, f_trc_log, f_trc_err, f_stat_log, f_stat_err]

for i in range(len(f_list)):
   if os.path.isfile(f_list[i].name):
       os.remove(f_list[i].name)

  """,
 'expected_stdout': 
  """
    Check fetches2dp_gtt_del: OK
    Check fetches2dp_gtt_sav: OK
    Check fetches2rows_gtt_del: OK
    Check fetches2rows_gtt_sav: OK
    Check marks2dp_gtt_del: OK
    Check marks2dp_gtt_sav: OK
    Check marks2rows_gtt_del: OK
    Check marks2rows_gtt_sav: OK
  """,
 'expected_stderr': 
  """
  """
}
]
}
