{
'id': 'bugs.core_5087',
'qmid': None,
'tracker_id': 'CORE-5087',
'title': 'Database shutdown can cause server crash if multiple attachments run EXECUTE STATEMENT',
'description': 
 """
   Test makes copy of current database file (see below 'bk_file') and establishes "checking" attachment to it (see 'att_chk').
   The fact that this attachment was just successfully established is logged by saving text 'check_point_1' in file (see 'f_chk_log').
   After this, test starts in child processes dozen of ISQL attachments; every of them does infinite loop with ES.
   
   We make some delay after that so all attachments can be fully involved in their job, i.e. can really do some ES.
   After that we begin to move database to shutdown and return it after to online state.
   Finally, we recall about our "checking" attachment ('att_chk'), return to it and try to CONTINUE work there by issuing second
   query to RDB$DATABASE and storing output as 'check_point_2'.

   The main idea is following: if Firebird is alive then we do NOT get exception on this step and f_chk_log should contain 
   TWO messages: 'check_point_1' and 'check_point_2', and no text like 'error reading connection'.
   
   Also, we do two additional checks:
   1. All ISQL sessions should be disconnected with writing to logs appropriate messages about shutdown.
       But their logs should NOT contain line with SQLSTATE = 08004 - and we'll check this.
   2. Also, we get difference between 'old' and 'current' versions of firebird.log and search in it for text
      that can also point on FB crash: "terminated abnormally".

   Checked on WI-V3.0.0.32320, SS/SC/CS.
   Estimated time for 3.0: SS = 19", SC = 19", CS = 31".   
   
   ::: NB :::. 

   On 2.5 no crash but works VERY slow, even for 5 attachments (checked on WI-V2.5.6.26970, 255 seconds!).
   Setting min_version = 2.6.6 is deferred again until CORE-5106 will not be fixed.

   Refactored 20.02.2020: replaced logic of waiting for all ISQL sessions be ready to do their work (inserts):
   use table T_LOCK(id int primary key), run aux. attachments (att1) and lock single record in this table.
   Then launch all planned ISQLs and make them try to insert duplicate into this table. All of them will stay in pause since this time.
   Wait several seconds, then switch to 'att1' and release record. All launched ISQL sesions will immediately work together at this point.

   Checked on:
        4.0.0.1779 CS: 16.108s.
        4.0.0.1766 SC: 15.643s.
        4.0.0.1773 CS: 18.420s.
        3.0.6.33251 SS: 16.495s.
        3.0.6.33247 SC: 13.891s.
        3.0.6.33247 CS: 16.804s.
 """,
'min_versions': '3.0',
'versions': [
{
 'firebird_version': '3.0',
 'platform': 'All',
 'init_script':
  """
    create sequence g;
    recreate table test(
        id int, 
        s varchar(500) unique, 
        att bigint default current_connection
    );
    recreate table log4attach(
        att bigint default current_connection
        ,dts timestamp default 'now'
        ,process varchar(255)
        ,protocol varchar(255)
        ,address varchar(255)
    );
    commit;

    set term ^;
    execute block as
    begin
        rdb$set_context('USER_SESSION','INITIAL_DDL','1');
    end
    ^
    	
    create or alter trigger trg_attach active on connect position 0 as
    begin
        if ( rdb$get_context('USER_SESSION','INITIAL_DDL') is null ) 
        then
            in autonomous transaction do 
                insert into log4attach(process,protocol, address)
                values(  rdb$get_context('SYSTEM', 'CLIENT_PROCESS')
                        ,rdb$get_context('SYSTEM', 'NETWORK_PROTOCOL') 
                        ,rdb$get_context('SYSTEM', 'CLIENT_ADDRESS') 
                      );
    end
    ^ -- trg_attach
    set term ;^
    commit;

    create index test_att on test(att);
    create index test_id on test(id);
    create index log4attach_att on log4attach(att);
    commit;
  """,
 'test_type': 'Python',
 'test_script': 
  """\
import os
import sys
import subprocess
from subprocess import Popen
import time
import shutil
import difflib
import fdb

def svc_get_fb_log( engine, f_fb_log ):

  import subprocess

  if engine.startswith('2.5'):
      get_firebird_log_key='action_get_ib_log'
  else:
      get_firebird_log_key='action_get_fb_log'

  subprocess.call([ "fbsvcmgr",
                    "localhost:service_mgr",
                    get_firebird_log_key
                  ],
                   stdout=f_fb_log, stderr=subprocess.STDOUT
                 )

  return

os.environ["ISC_USER"] = user_name
os.environ["ISC_PASSWORD"] = user_password

db_file=db_conn.database_name
engine = str(db_conn.engine_version)

db_conn.close()

bk_file="$(DATABASE_LOCATION)tmp_5087_chk4alive.fdb"

# Copy database to another file in order to make connect to this copy
# and check that this connection is alive after we'll do DML and shutdown
# with source database (i.e. with "bugs.core_5087.fdb"):
shutil.copy2( db_file, bk_file )

att_chk = fdb.connect(dsn='localhost:'+bk_file) # This leads to adding 1 row into table 'log4attach'

att_chk.begin()
cur_chk = att_chk.cursor()
cur_chk.execute("select 'check_point_1' as msg from rdb$database")

f_chk_log = open( os.path.join(context['temp_directory'],'tmp_chk_5087.log'), 'w', buffering=0)

for row in cur_chk:
    f_chk_log.write(row[0])

att_chk.commit()


# Obtain engine version:

att1 = fdb.connect(dsn=dsn)

att1.execute_immediate('recreate table t_lock(id int primary key)')
att1.commit()
att1.execute_immediate('insert into t_lock(id) values(1)')

# att1.close()

f_fblog_before=open( os.path.join(context['temp_directory'],'tmp_5087_fblog_before.txt'), 'w', buffering=0)
svc_get_fb_log( engine, f_fblog_before )
f_fblog_before.close()

sql_dml=\
'''
    commit;
    set transaction wait;
    set term ^;
    execute block as
    begin
        insert into t_lock(id) values(1);
        when any do
        begin
         -- nop --
        end
    end
    ^
    set term ;^
    commit;

    set transaction read committed;
    set term ^;
    execute block as
        declare n_limit int = 1000000;
        declare s_length smallint;
    begin
        select ff.rdb$field_length
        from rdb$fields ff
        join rdb$relation_fields rf on ff.rdb$field_name = rf.rdb$field_source
        where rf.rdb$relation_name=upper('test') and rf.rdb$field_name=upper('s')
        into s_length;

        while (n_limit > 0) do
        begin
            execute statement ('insert into test(id, s) values( ?, ?)')
                  ( gen_id(g,1), rpad('', :s_length, uuid_to_char(gen_uuid()))  )
                  with autonomous transaction
            ;

            n_limit = n_limit - 1;
        end
        insert into test( id ) values( -current_connection );
    end
    ^
    set term ;^
    commit;
'''

f_dml_sql = open( os.path.join(context['temp_directory'],'tmp_dml_5087.sql'), 'w', buffering=0)
f_dml_sql.write(sql_dml)
f_dml_sql.close()

f_list = []
p_list = []

########################################################
#  Launching dozen of child ISQL processes with doing ES
########################################################

planned_dml_attachments = 30

for i in range(0, planned_dml_attachments):
    sqllog=open( os.path.join(context['temp_directory'],'tmp_dml_5087_'+str(i)+'.log'), 'w', buffering=0)
    f_list.append(sqllog)

for i in range(len(f_list)):
    ###########################################
    #   a s y n c h r o n o u s     l a u n c h
    ###########################################
    p_isql=Popen( [ "isql" , "localhost:"+db_file, "-i", f_dml_sql.name ],
                  stdout=f_list[i],
                  stderr=subprocess.STDOUT
                )
    p_list.append(p_isql)


# Delay: let ISQL sessions do establish their attachments
time.sleep( 3 )

# release t_lock record.
# All launched ISQL sessions can do useful job (INSERT statements) since this point.
att1.close()

# Let ISQL sessions do some work:
time.sleep( 5 )

f_shutdown_log = open( os.path.join(context['temp_directory'],'tmp_shutdown_5087.log'), 'w', buffering=0)

####################################
# S H U T D O W N    D A T A B A S E
####################################

subprocess.call( ["fbsvcmgr","localhost:service_mgr",
                  "action_properties",
                  "dbname", db_file,
                  "prp_shutdown_mode", "prp_sm_full", "prp_force_shutdown", "0"
                 ],
                 stdout=f_shutdown_log,
                 stderr=subprocess.STDOUT
               )

# ...and return it to ONLINE because fbtest will try to remove it on exit from here:
subprocess.call( ["fbsvcmgr", "localhost:service_mgr",
                  "action_properties", "prp_db_online",
                  "dbname", db_file,
                 ],
                 stdout = f_shutdown_log,
                 stderr = subprocess.STDOUT
               )
f_shutdown_log.close()


for i in range(len(f_list)):
    f_list[i].close()

for i in range(len(p_list)):
    p_list[i].terminate()

# Here we must wait a little because firebird.log will get new messages NOT instantly.
time.sleep(3)

crashes_in_worker_logs = 0
for i in range(len(f_list)):
    dml_worker_log=open(f_list[i].name).read()
    if 'SQLSTATE = 08004' in dml_worker_log: #### do NOT add >>> or 'SQLSTATE = 08006' in dml_worker_log:
        crashes_in_worker_logs += 1
    os.remove(f_list[i].name)

f_fblog_after=open( os.path.join(context['temp_directory'],'tmp_5087_fblog_after.txt'), 'w', buffering=0)
svc_get_fb_log( engine, f_fblog_after )
f_fblog_after.close()

att_chk.begin()
cur_chk.execute("select 'check_point_2' as msg from rdb$database")

f_chk_log.seek(0,2)
for row in cur_chk:
    f_chk_log.write('\\n')
    f_chk_log.write(row[0])

f_chk_log.seek(0,2)
f_chk_log.write('\\n')
f_chk_log.write('Found crash messages in DML worker logs: ' + str(crashes_in_worker_logs))

sql_chk=\
'''
    set list on;
    set count on;
    select iif( count(distinct att) = %(planned_dml_attachments)s, 'YES', 'NO. Only ' || count(distinct att) || ' attachments of planned %(planned_dml_attachments)s established.' ) as "All_workers_found ?"
    from (
        select 
            att
            ,count( iif(id >=0, id, null) ) as cnt_in_autonom_tx
            ,count( iif(id < 0, id, null) ) as cnt_in_common_tx
        from test 
        group by att
    )
    where cnt_in_common_tx = 0 and cnt_in_autonom_tx > 0;
''' % locals()

f_chk_sql = open( os.path.join(context['temp_directory'],'tmp_chk_5087.sql'), 'w', buffering=0)
f_chk_sql.write(sql_chk)
f_chk_sql.close()

f_chk_log.seek(0,2)
subprocess.call( [ "isql" , "localhost:"+db_file, "-nod", "-i", f_chk_sql.name ],
                  stdout=f_chk_log,
                  stderr=subprocess.STDOUT
                )


att_chk.commit()
att_chk.close()

os.remove(bk_file)

f_chk_log.close()

# Now we can compare two versions of firebird.log and check their difference.

oldfb=open(f_fblog_before.name, 'r')
newfb=open(f_fblog_after.name, 'r')

difftext = ''.join(difflib.unified_diff(
    oldfb.readlines(), 
    newfb.readlines()
  ))
oldfb.close()
newfb.close()

f_diff_txt=open( os.path.join(context['temp_directory'],'tmp_5087_diff.txt'), 'w')
f_diff_txt.write(difftext)
f_diff_txt.close()

with open( f_diff_txt.name,'r') as f:
    for line in f:
        if line.startswith('+') and 'terminated abnormally' in line:
            print('Crash message in firebird.log detected: '+line.upper())
f.close()

# This should be empty:
#######################
with open( f_shutdown_log.name,'r') as f:
    for line in f:
        print(line.upper())
f.close()

# Print check info:
with open( f_chk_log.name,'r') as f:
  print( f.read() )
f.close()

###############################
# Cleanup.

k_list = [ f_shutdown_log, f_dml_sql, f_chk_sql, f_fblog_before, f_fblog_after, f_diff_txt, f_chk_log ]
for i in range(len(k_list)):
    if os.path.isfile(k_list[i].name):
        os.remove(k_list[i].name)

  """,
 'expected_stdout':
  """
    check_point_1
    check_point_2
    Found crash messages in DML worker logs: 0
    All_workers_found ?             YES
    Records affected: 1
  """,
 'expected_stderr':
  """
  """
}
]
}
