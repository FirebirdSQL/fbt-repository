{
'id': 'tests.functional.replication.ddl-triggers-must-not-fire-on-replica',
'qmid': None,
'tracker_id': '',
'title': "Replica DB must not fire DDL-level triggers but their activity on master must be eventually seen in replica.",
'description':
 """
    Test creates all kinds of DDL triggers in the master DB.
    Each of them registers apropriate event in the table with name 'log_ddl_triggers_activity'.
    This table must eventually have records for all DDL events in BOTH databases (i.e. not only in master, but in replica also).
    After this we create all kinds of DB objects (tables, procedure, function, etc) in master DB to fire these triggers.

    Then we wait until replica becomes actual to master, and this delay will last no more then threshold
    that is defined by MAX_TIME_FOR_WAIT_SEGMENT_IN_LOG variable (measured in seconds).
    During this delay, we check every second for replication log and search there line with number of last generated
    segment (which was replicated and deleting finally).
    We can assume that replication finished OK only when such line is found see ('POINT-1').
    
    After this, we do query master and replica databases and obtain data from 'log_ddl_triggers_activity' table: it must
    have records about every fired trigger. Content of this table must be identical on master and replica, see queries
    to v_log_ddl_triggers_activity (both on master and replica DB).

    Then we invoke ISQL with executing auxiliary script for drop all DB objects on master (with '-nod' command switch).
    After all objects will be dropped, we have to wait again until  replica becomes actual with master (see 'POINT-2').

    Finally, we extract metadata for master and replica and compare them (see 'f_meta_diff').
    The only difference in metadata must be 'CREATE DATABASE' statement with different DB names - we suppress it,
    thus metadata difference must not be issued.

    ################
    ### N O T E  ###
    ################
    Test assumes that master and replica DB have been created beforehand.
    Also, it assumes that %FB_HOME%\replication.conf has been prepared with apropriate parameters for replication.
    Particularly, name of directories and databases must have info about checked FB major version and ServerMode.
        * verbose = true // in order to find out line with message that required segment was replicated
        * section for master database with specified parameters:
            journal_directory = "!fbt_repo!\tmp\fb-replication.!fb_major!.!server_mode!.journal"
            journal_archive_directory = "!fbt_repo!\tmp\fb-replication.!fb_major!.!server_mode!.archive"
            journal_archive_command = "copy $(pathname) $(archivepathname)"
            journal_archive_timeout = 10
        * section for replica database with specified parameter:
             journal_source_directory =  "!fbt_repo!\tmp\fb-replication.!fb_major!.!server_mode!.archive"

    Master and replica databases must be created in "!fbt_repo!\tmp\" directory and have names like these:
        'fbt-main.fb40.SS.fdb'; 'fbt-repl.fb40.SS.fdb'; - for FB 4.x ('SS' = Super; 'CS' = Classic)
        'fbt-main.fb50.SS.fdb'; 'fbt-repl.fb50.SS.fdb'; - for FB 5.x ('SS' = Super; 'CS' = Classic)
        NB: fixed numeric value ('40' or '50') must be used for any minor FB version (4.0; 4.0.1; 4.1; 5.0; 5.1 etc)

    These two databases must NOT be dropped in any of tests related to replication!
    They are created and dropped in the batch scenario which prepares FB instance to be checked for each ServerMode
    and make cleanup after it, i.e. when all tests will be completed.

    NB. Currently this task was implemented only in Windows batch, thus test has attribute platform = 'Windows'.

    Temporary comment. For debug purpoces:
        1) find out SUFFIX of the name of FB service which is to be tested (e.g. 'DefaultInstance', '40SS' etc);
        2) copy file %fbt-repo%\tests\functional\tabloid\batches\setup-fb-for-replication.bat.txt
           to some place and rename it "*.bat";
        3) open this .bat in editor and asjust value of 'fbt_repo' variable;
        4) run: setup-fb-for-replication.bat [SUFFIX_OF_FB_SERVICE]
           where SUFFIX_OF_FB_SERVICE is ending part of FB service which you want to check:
           DefaultInstance ; 40ss ; 40cs ; 50ss ; 50cs etc
        5) batch 'setup-fb-for-replication.bat' will:
           * stop selected FB instance
           * create test databases (in !fbt_repo!\tmp\);
           * prepare journal/archive sub-folders for replication (also in !fbt_repo!\tmp\);
           * replace %fb_home%\replication.conf with apropriate
           * start selected FB instance
        6) run this test (FB instance will be already launched by setup-fb-for-replication.bat):
            %fpt_repo%\fbt-run2.bat ddl-triggers-must-not-fire-on-replica.fbt 50ss, etc

    Checked on:
        4.0.1.2519 SS: 56.48s, CS: 99.31s
        5.0.0.82   SS: 20.63s, CS: 21.39s
 """,
'min_versions': '4.0',
'versions': [
{
 'firebird_version': '4.0',
 'platform': 'Windows',
 'database_character_set': 'UTF8',
 'connection_character_set': 'UTF8',
 'init_script':
  """
  """,
 'test_type': 'Python',
 'test_script': 
  """
import os
import subprocess
import re
import difflib
import shutil
import time

os.environ["ISC_USER"] = user_name
os.environ["ISC_PASSWORD"] = user_password

#####################################
MAX_TIME_FOR_WAIT_SEGMENT_IN_LOG = 65
#####################################

svc = fdb.services.connect(host='localhost', user=user_name, password=user_password)
FB_HOME = svc.get_home_directory()
svc.close()

engine = db_conn.engine_version         # 4.0; 4.1; 5.0 etc -- type float
fb_major = 'fb' + str(engine)[:1] + '0' # 'fb40'; 'fb50'

cur = db_conn.cursor()
cur.execute("select rdb$config_value from rdb$config where upper(rdb$config_name) = upper('ServerMode')")
server_mode = 'XX'
for r in cur:
    if r[0] == 'Super':
        server_mode = 'SS'
    elif r[0] == 'SuperClassic':
        server_mode = 'SC'
    elif r[0] == 'Classic':
        server_mode = 'CS'
cur.close()

# 'fbt-main.fb50.ss.fdb' etc:
db_main = os.path.join( context['temp_directory'], 'fbt-main.' + fb_major + '.' + server_mode + '.fdb' )
db_repl = db_main.replace( 'fbt-main.', 'fbt-repl.')

# Folders for journalling and archieving segments.
repl_journal_dir = os.path.join( context['temp_directory'], 'fb-replication.' + fb_major + '.' + server_mode + '.journal' )
repl_archive_dir = os.path.join( context['temp_directory'], 'fb-replication.' + fb_major + '.' + server_mode +  '.archive' )

db_conn.close()

#--------------------------------------------

def flush_and_close( file_handle ):
    # https://docs.python.org/2/library/os.html#os.fsync
    # If you're starting with a Python file object f,
    # first do f.flush(), and
    # then do os.fsync(f.fileno()), to ensure that all internal buffers associated with f are written to disk.
    global os

    file_handle.flush()
    if file_handle.mode not in ('r', 'rb') and file_handle.name != os.devnull:
        # otherwise: "OSError: [Errno 9] Bad file descriptor"!
        os.fsync(file_handle.fileno())
    file_handle.close()

#--------------------------------------------

def cleanup( f_names_list ):
    global os
    for i in range(len( f_names_list )):
       if type(f_names_list[i]) == file:
          del_name = f_names_list[i].name
       elif type(f_names_list[i]) == str:
          del_name = f_names_list[i]
       else:
          print('Unrecognized type of element:', f_names_list[i], ' - can not be treated as file.')
          del_name = None

       if del_name and os.path.isfile( del_name ):
           os.remove( del_name )

#--------------------------------------------

def wait_for_data_in_replica( fb_home, max_allowed_time_for_wait, db_main, prefix_msg = '' ):

    global re
    global difflib
    global time

    replold_lines = []
    with open( os.path.join(fb_home,'replication.log'), 'r') as f:
        replold_lines = f.readlines()

    con = fdb.connect( dsn = 'localhost:' + db_main, no_db_triggers = 1)
    cur = con.cursor()
    cur.execute("select rdb$get_context('SYSTEM','REPLICATION_SEQUENCE') from rdb$database")
    for r in cur:
        last_generated_repl_segment = r[0]
    cur.close()
    con.close()

    #print('last_generated_repl_segment:', last_generated_repl_segment)

    # VERBOSE: Segment 1 (2582 bytes) is replicated in 1 second(s), deleting the file
    p=re.compile( '\+\s+verbose:\s+segment\s+%(last_generated_repl_segment)s\s+\(\d+\s+bytes\)\s+is\s+replicated.*deleting' % locals(), re.IGNORECASE)

    found_required_message = False
    for i in range(0,max_allowed_time_for_wait):
        time.sleep(1)
     
        # Get content of fb_home replication.log _after_ isql finish:
        f_repllog_new = open( os.path.join(fb_home,'replication.log'), 'r')
        diff_data = difflib.unified_diff(
            replold_lines, 
            f_repllog_new.readlines()
          )
        f_repllog_new.close()

        for k,d in enumerate(diff_data):
            if p.search(d):
                print( (prefix_msg + ' ' if prefix_msg else '') + 'FOUND message about replicated segment.' )
                found_required_message = True
                break

        if found_required_message:
            break

    if not found_required_message:
        print('UNEXPECTED RESULT: no message about replicated segment for %d seconds.' % max_allowed_time_for_wait)

#--------------------------------------------

sql_ddl = '''\
    set bail on;
    set list on;
    
    select mon$database_name from mon$database;

    recreate table log_ddl_triggers_activity (
        id int generated by default as identity constraint pk_log_ddl_triggers_activity primary key
        ,ddl_trigger_name varchar(64)
        ,event_type varchar(25) not null
        ,object_type varchar(25) not null
        ,ddl_event varchar(25) not null
        ,object_name varchar(64) not null
    );


    set term ^;
    execute block as
        declare v_lf char(1) = x'0A';
    begin
        rdb$set_context('USER_SESSION', 'SKIP_DDL_TRIGGER', '1');

        for
            with
            a as (
                select 'ANY DDL STATEMENT' x from rdb$database union all
                select 'CREATE TABLE' from rdb$database union all
                select 'ALTER TABLE' from rdb$database union all
                select 'DROP TABLE' from rdb$database union all
                select 'CREATE PROCEDURE' from rdb$database union all
                select 'ALTER PROCEDURE' from rdb$database union all
                select 'DROP PROCEDURE' from rdb$database union all
                select 'CREATE FUNCTION' from rdb$database union all
                select 'ALTER FUNCTION' from rdb$database union all
                select 'DROP FUNCTION' from rdb$database union all
                select 'CREATE TRIGGER' from rdb$database union all
                select 'ALTER TRIGGER' from rdb$database union all
                select 'DROP TRIGGER' from rdb$database union all
                select 'CREATE EXCEPTION' from rdb$database union all
                select 'ALTER EXCEPTION' from rdb$database union all
                select 'DROP EXCEPTION' from rdb$database union all
                select 'CREATE VIEW' from rdb$database union all
                select 'ALTER VIEW' from rdb$database union all
                select 'DROP VIEW' from rdb$database union all
                select 'CREATE DOMAIN' from rdb$database union all
                select 'ALTER DOMAIN' from rdb$database union all
                select 'DROP DOMAIN' from rdb$database union all
                select 'CREATE ROLE' from rdb$database union all
                select 'ALTER ROLE' from rdb$database union all
                select 'DROP ROLE' from rdb$database union all
                select 'CREATE SEQUENCE' from rdb$database union all
                select 'ALTER SEQUENCE' from rdb$database union all
                select 'DROP SEQUENCE' from rdb$database union all
                select 'CREATE USER' from rdb$database union all
                select 'ALTER USER' from rdb$database union all
                select 'DROP USER' from rdb$database union all
                select 'CREATE INDEX' from rdb$database union all
                select 'ALTER INDEX' from rdb$database union all
                select 'DROP INDEX' from rdb$database union all
                select 'CREATE COLLATION' from rdb$database union all
                select 'DROP COLLATION' from rdb$database union all
                select 'ALTER CHARACTER SET' from rdb$database union all
                select 'CREATE PACKAGE' from rdb$database union all
                select 'ALTER PACKAGE' from rdb$database union all
                select 'DROP PACKAGE' from rdb$database union all
                select 'CREATE PACKAGE BODY' from rdb$database union all
                select 'DROP PACKAGE BODY' from rdb$database
            )
            ,e as (
                select 'before' w from rdb$database union all select 'after' from rdb$database
            )
            ,t as (
                select upper(trim(replace(trim(a.x),' ','_')) || iif(e.w='before', '_before', '_after')) as trg_name, a.x, e.w
                from e, a
            )

            select
                   'create or alter trigger trg_' || t.trg_name
                || ' active ' || t.w || ' ' || trim(t.x) || ' as '
                || :v_lf
                || 'begin'
                || :v_lf
                || q'{    if (rdb$get_context('USER_SESSION', 'SKIP_DDL_TRIGGER') is null) then}'
                || :v_lf
                || '        insert into log_ddl_triggers_activity(ddl_trigger_name, event_type, object_type, ddl_event, object_name) values('
                || :v_lf
                || q'{'}' || trim(t.trg_name) || q'{'}'
                || :v_lf
                || q'{, rdb$get_context('DDL_TRIGGER', 'EVENT_TYPE')}'
                || :v_lf
                || q'{, rdb$get_context('DDL_TRIGGER', 'OBJECT_TYPE')}'
                || :v_lf
                || q'{, rdb$get_context('DDL_TRIGGER', 'DDL_EVENT')}'
                || :v_lf
                || q'{, rdb$get_context('DDL_TRIGGER', 'OBJECT_NAME')}'
                || :v_lf
                || ');'
                || :v_lf
                || ' end'
                as sttm
            from t
            as cursor c
         do begin
             execute statement(c.sttm) with autonomous transaction;
         end

        rdb$set_context('USER_SESSION', 'SKIP_DDL_TRIGGER', null);
    end
    ^
    set term ;^
    commit;

    /*
    select rt.rdb$trigger_name,rt.rdb$relation_name,rt.rdb$trigger_type,rt.rdb$trigger_source
    from rdb$triggers rt
    where
        rt.rdb$system_flag is distinct from 1
        and rt.rdb$trigger_inactive is distinct from 1;

    select * from log_ddl_triggers_activity;
    */

    set count on;
    set echo on;

    ----------
    create table test(id int not null);
    alter table test add constraint test_pk primary key(id);
    drop table test;
    ----------
    set term ^;
    create procedure sp_test as begin end
    ^
    alter procedure sp_test as declare x int; begin x=1; end
    ^
    drop procedure sp_test
    ^
    ----------
    create function fn_test(a_id int) returns bigint as
    begin
        return a_id * a_id;
    end
    ^
    alter function fn_test(a_id int) returns int128 as
    begin
        return a_id * a_id * a_id;
    end
    ^
    drop function fn_test
    ^
    ----------
    create trigger trg_connect_test on connect as
    begin
    end
    ^
    alter trigger trg_connect_test as
        declare x int;
    begin
        x = 1;
    end
    ^
    drop trigger trg_connect_test
    ^
    ----------
    create exception exc_test 'Invalud value: @1'
    ^
    alter exception exc_test 'Bad values: @1 and @2'
    ^
    drop exception exc_test
    ^
    ----------
    create view v_test as select 1 x from rdb$database
    ^
    alter view v_test as select 1 x, 2 y from rdb$database
    ^
    drop view v_test
    ^
    ----------
    create domain dm_test int
    ^
    alter domain dm_test set not null
    ^
    drop domain dm_test
    ^
    ----------
    create role r_test
    ^
    alter role r_test set system privileges to use_gstat_utility, ignore_db_triggers
    ^
    drop role r_test
    ^
    ----------
    create sequence g_test
    ^
    alter sequence g_test restart with 123
    ^
    drop sequence g_test
    ^
    ----------
    create user u_test password '123' using plugin Srp
    ^
    alter user u_test password '456'
    ^
    drop user u_test
    ^
    ----------
    create index idx_test on rdb$user_privileges(rdb$field_name)
    ^
    alter index idx_test inactive
    ^
    drop index idx_test
    ^
    ----------
    create collation name_coll for utf8 from unicode case insensitive
    ^

    drop collation name_coll
    ^
    ----------
    alter character set iso8859_1 set default collation pt_br
    ^
    ----------
    create or alter package pg_test as
    begin
       function pg_fn1 returns int;
    end
    ^
    alter package pg_test as
    begin
       function pg_fn1(a_x int) returns int128;
    end
    ^

    create package body pg_test as
    begin
       function pg_fn1(a_x int) returns int128 as
       begin
           return a_x * a_x * a_x;
       end
    end
    ^

    drop package body pg_test
    ^
    drop package pg_test
    ^
    set term ;^
    commit;


    select rdb$get_context('SYSTEM','REPLICATION_SEQUENCE') as last_generated_repl_segment from rdb$database;
    quit;
''' % locals()


f_sql_chk = open( os.path.join(context['temp_directory'],'tmp_repltest_skip_ddl_trg.sql'), 'w')
f_sql_chk.write(sql_ddl)
flush_and_close( f_sql_chk )

f_sql_log = open( ''.join( (os.path.splitext(f_sql_chk.name)[0], '.log' ) ), 'w')
f_sql_err = open( ''.join( (os.path.splitext(f_sql_chk.name)[0], '.err' ) ), 'w')
subprocess.call( [ context['isql_path'], 'localhost:' + db_main, '-i', f_sql_chk.name ], stdout = f_sql_log, stderr = f_sql_err)
flush_and_close( f_sql_log )
flush_and_close( f_sql_err )

with open(f_sql_err.name,'r') as f:
    for line in f:
        print('UNEXPECTED STDERR in initial SQL: ' + line)
        MAX_TIME_FOR_WAIT_SEGMENT_IN_LOG = 0


if MAX_TIME_FOR_WAIT_SEGMENT_IN_LOG: # ==> initial SQL script finished w/o errors

    ##############################################################################
    ###  W A I T   U N T I L    R E P L I C A    B E C O M E S   A C T U A L   ###
    ##############################################################################
    wait_for_data_in_replica( FB_HOME, MAX_TIME_FOR_WAIT_SEGMENT_IN_LOG, db_main, 'POINT-1' )
    

    sql_get_result =\
    '''
        set list on;
        set count on;
        select
            iif(coalesce(rdb$get_context('SYSTEM','REPLICA_MODE'),'') = '', 'MASTER', 'REPLICA') as replication_mode
            ,id
            ,ddl_trigger_name
            ,event_type
            ,object_type
            ,ddl_event
            ,object_name
        from log_ddl_triggers_activity
        order by id;
    '''

    runProgram('isql', ['localhost:' + db_main, '-nod'], sql_get_result)
    runProgram('isql', ['localhost:' + db_repl, '-nod'], sql_get_result)

'''

# return initial state of master DB:
# remove all DB objects (tables, views, ...):
# --------------------------------------------
sql_clean_ddl = os.path.join(context['files_location'],'drop-all-db-objects.sql')

f_clean_log=open( os.path.join(context['temp_directory'],'drop-all-db-objects.log'), 'w')
f_clean_err=open( ''.join( ( os.path.splitext(f_clean_log.name)[0], '.err') ), 'w')
subprocess.call( [context['isql_path'], 'localhost:' + db_main, '-q', '-nod', '-i', sql_clean_ddl], stdout=f_clean_log, stderr=f_clean_err )
flush_and_close(f_clean_log)
flush_and_close(f_clean_err)

with open(f_clean_err.name,'r') as f:
    for line in f:
        print('UNEXPECTED STDERR in cleanup SQL: ' + line)
        MAX_TIME_FOR_WAIT_SEGMENT_IN_LOG = 0

with open(f_clean_log.name,'r') as f:
    for line in f:
        # show number of dropped objects
        print(line)

if MAX_TIME_FOR_WAIT_SEGMENT_IN_LOG: # ==> initial SQL script finished w/o errors

    ##############################################################################
    ###  W A I T   U N T I L    R E P L I C A    B E C O M E S   A C T U A L   ###
    ##############################################################################
    wait_for_data_in_replica( FB_HOME, MAX_TIME_FOR_WAIT_SEGMENT_IN_LOG, db_main, 'POINT-2' )

    f_main_meta_sql=open( os.path.join(context['temp_directory'],'db_main_meta.sql'), 'w')
    subprocess.call( [context['isql_path'], 'localhost:' + db_main, '-q', '-nod', '-ch', 'utf8', '-x'], stdout=f_main_meta_sql, stderr=subprocess.STDOUT )
    flush_and_close( f_main_meta_sql )

    f_repl_meta_sql=open( os.path.join(context['temp_directory'],'db_repl_meta.sql'), 'w')
    subprocess.call( [context['isql_path'], 'localhost:' + db_repl, '-q', '-nod', '-ch', 'utf8', '-x'], stdout=f_repl_meta_sql, stderr=subprocess.STDOUT )
    flush_and_close( f_repl_meta_sql )

    db_main_meta=open(f_main_meta_sql.name, 'r')
    db_repl_meta=open(f_repl_meta_sql.name, 'r')

    diffmeta = ''.join(difflib.unified_diff(
        db_main_meta.readlines(), 
        db_repl_meta.readlines()
      ))
    db_main_meta.close()
    db_repl_meta.close()

    f_meta_diff=open( os.path.join(context['temp_directory'],'db_meta_diff.txt'), 'w', buffering = 0)
    f_meta_diff.write(diffmeta)
    flush_and_close( f_meta_diff )

    # Following must issue only TWO rows:
    #     UNEXPECTED METADATA DIFF.: -/* CREATE DATABASE 'localhost:[db_main]' ... */
    #     UNEXPECTED METADATA DIFF.: -/* CREATE DATABASE 'localhost:[db_repl]' ... */
    # Only thes lines will be suppressed further (see subst. section):
    with open(f_meta_diff.name, 'r') as f:
        for line in f:
           if line[:1] in ('-', '+') and line[:3] not in ('---','+++'):
               print('UNEXPECTED METADATA DIFF.: ' + line)

'''

# cleanup:
##########
#cleanup( (f_sql_chk, f_sql_log, f_sql_err,f_clean_log,f_clean_err,f_main_meta_sql,f_repl_meta_sql,f_meta_diff) )
  
  """,
 'expected_stdout':
  """
  """,
 'expected_stderr':
  """
  """,
 'substitutions': [
     ('Start removing objects in:.*', 'Start removing objects')
    ,('Finish. Total objects removed:  [1-9]\d*', 'Finish. Total objects removed')
    ,('.* CREATE DATABASE .*', '')
  ]
}
]
}
